{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Insurance Challenge ##\n",
    "\n",
    "Welcome to the Insurance Challenge! The data for this challenge can be found here, on Kaggle: https://www.kaggle.com/c/prudential-life-insurance-assessment. See this link for data download and a description of each variable.\n",
    "\n",
    "In this challenge, you will use a large number of variables in a tabular data set to categorize the risk level of a person buying insurance. For newcomers, we will walk you through the process of how to build a machine learning model. For more experienced members, we will discuss Grid Search Hyperparameter optimization and gradient boosting models. Let's start by reading in the data and the Python packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>E1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>D2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   2               1             D3              10        0.076923   \n",
       "1   5               1             A1              26        0.076923   \n",
       "2   6               1             E1              26        0.076923   \n",
       "3   7               1             D4              10        0.487179   \n",
       "4   8               1             D2              26        0.230769   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  ...  \\\n",
       "0               2               1               1  0.641791  0.581818  ...   \n",
       "1               2               3               1  0.059701  0.600000  ...   \n",
       "2               2               3               1  0.029851  0.745455  ...   \n",
       "3               2               3               1  0.164179  0.672727  ...   \n",
       "4               2               3               1  0.417910  0.654545  ...   \n",
       "\n",
       "   Medical_Keyword_40  Medical_Keyword_41  Medical_Keyword_42  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_43  Medical_Keyword_44  Medical_Keyword_45  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_46  Medical_Keyword_47  Medical_Keyword_48  Response  \n",
       "0                   0                   0                   0         8  \n",
       "1                   0                   0                   0         4  \n",
       "2                   0                   0                   0         8  \n",
       "3                   0                   0                   0         8  \n",
       "4                   0                   0                   0         8  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that this data needs some cleaning since some variables have many NA values or cannot be used.\n",
    "\n",
    "#Start by finding all columns with NA\n",
    "test = df.isna().sum()\n",
    "drop = pd.Series(test[test != 0].index)\n",
    "\n",
    "#Pick out the variables that you want to drop - \n",
    "# these include columns with no NA, as well as columns with irrelevant data such as \"ID\" or the variable you are predicting\n",
    "\n",
    "X = df.drop(pd.concat([drop, pd.Series([\"Product_Info_2\",\"Id\",\"Response\"])]), axis = 1)\n",
    "\n",
    "#Set the response that you are predicting as its own variable.\n",
    "y = df.Response\n",
    "\n",
    "#Feel free to run a cell with just \"X\" or \"y\" in it to see what these look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split ###\n",
    "\n",
    "For evaluating a machine learning model, you must split the data into training and testing. By doing this, you ensure that the model is evaluated on data that it has *not* yet seen. This is important because, in the real world, you won't know what the actual label is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #1: Basic Machine Learning ##\n",
    "\n",
    "Our goal is to classify each observation into a risk level, which is defined by the \"Response\" variable. This is a supervised ML problem, because we are teaching the algorithm using pre-labeled training data. Of the two types of supervised ML problems, classification and regression, this is considered \"classification\" because we are predicting one of eight discrete outcome (a regression problem would predict a continuous outcome). \n",
    "\n",
    "Below are some commonly-used classification algorithms. Google them or follow the links to read the documentation and see what they are all about, and try picking two to compare. Don't forget to check out the examples!\n",
    "\n",
    "* [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [SVC (Support Vector Classifier)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "As an example, I will demonstrate a different classifier: [K-nearest-neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). In this algorithm, a point is predicted by looking at which class is the most frequent class in the \"neighborhood\" of the observation, or which class is most frequent among the \"k-nearest\" neighbors of the observation being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3516881367348657"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#First, we define the model and the parameters we want to use\n",
    "model = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "#Then, we fit to the training data using the \"fit\" function with the training data, \n",
    "# and obtain the accuracy via the \"score\" function with the testing data. \n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "#While the algorithm is only about ~35% accurate, this is based on a multi-class model of 8 classes - \n",
    "# so, if we guessed randomly, we would only expect to see about 12.5% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models have \"hyperparameters,\" which represent the parameters of the model that are not contained in the training data. For instance, KNeighborsClassifier has \"n_neighbors\" which tells the algorithm how many neighbors to consider. When training a machine learning model, it is a good idea to try different hyperparameters to see which ones work the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36120232381914624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try increasing the number of neighbors\n",
    "model = KNeighborsClassifier(n_neighbors = 20)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "#Looks like a small improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! Similar to the code above, try using different algorithms to train your model and get the highest possible accuracy. Also, trying using \"cross-validation\" to make sure you model works under different training data, and evaluating the model using different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #2: Hyperparameter Optimization ##\n",
    "\n",
    "Let's try a more scientific approach to this problem. You may be asking, \"with so many possible hyperparameters to pick, how can I find the best one?\" This article by sci-kit learn may solve your issues: https://scikit-learn.org/stable/modules/grid_search.html. Read this article to find out more.\n",
    "\n",
    "One of the most common methods to decide on a hyperparameter is using a grid search. In this, a grid of values is tested sequentially to see which is the best. An example using K-nearest-neighbors is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 10, 100, 1000]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"n_neighbors\": [1, 10, 100, 1000]}\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(model, params)\n",
    "\n",
    "#Only need X and y, since the model does cross-validation for us and splits into train and test automatically\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29344405, 0.35235176, 0.3559556 , 0.33569659])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we se the results for each point on the grid. Around 100 yielded the highest score\n",
    "grid.cv_results_['mean_test_score']\n",
    "\n",
    "#We can also do another grid search with more refined numbers, say with [80,90, 100, 110, 120] \n",
    "# to test more precisely once we have a good ballpark estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tested GridSearchCV, can you try another searching algorithm for refining your model's hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #3: Gradient Boosting Models ##\n",
    "\n",
    "The best models for tabular data in data science competitions are gradient-boosting algorithms. Gradient boosting algorithms use a loss function, which specifies error penalty, to sequentially add weaker predictors including linear models and tree-based models to the final model, similar to how a Random Forest uses many decision trees. See [here](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/) for more information.\n",
    "\n",
    "The final challenge is to train a gradient-boosting model for predicting insurance risk. XGBoost is one of the best models for tabular data. To use it, please see the documentation for installation instructions and how to get started, since it is a separate package from sklearn: https://xgboost.readthedocs.io/en/latest/get_started.html. You can also view the specific Python documentation [here](https://xgboost.readthedocs.io/en/latest/python/python_intro.html#data-interface) *Note that this is not available through Anaconda; you must install the package using pip*. I would highly recommend reading through the many parameters to get a sense for what it requires, and running some grid-search cross-validation to optimize the hyperparameters. Fair warning, though: Gradient boosters take longer to train than regular algorithms!\n",
    "\n",
    "For the more scientifically-inclined, feel free to check out https://arxiv.org/abs/1603.02754. This is the published paper descibring XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "#Read in data for format in XGBoost\n",
    "#Note we need to subtract 1 since classes in XGBoost start at 0\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train-1)\n",
    "dtest = xgb.DMatrix(X_test, label = y_test-1)\n",
    "\n",
    "#set up parameters by reading the documentation to figure out which ones you want to include\n",
    "#We use the softmax function as the objective, since we are doing multivariate classification\n",
    "#Note that I enable a GPU here since I have one; if you don't, remove the \"gpu_id\" and \"tree_method\" parameters.\n",
    "param = {'max_depth':5, \n",
    "         'eta':1, \n",
    "         'num_class':8, \n",
    "         'gpu_id':0,\n",
    "         'tree_method':'gpu_hist',\n",
    "         'objective':'multi:softmax' }\n",
    "num_round = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Train Model and make prediction.\n",
    "model = xgb.train(param, dtrain, num_round)\n",
    "preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5228593079060369"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the confusion matrix and the accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_test, preds+1)\n",
    "np.diag(conf).sum() / conf.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try experimenting with different parameters (listed [here](https://xgboost.readthedocs.io/en/latest/parameter.html)) to make the model as accurate as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
